---
status: new
comments: True
---

# VerboseImages [ICLR24]

!!! note "æ­£åœ¨æ–½å·¥ä¸­ğŸ‘·.. "


[![citation](https://img.shields.io/badge/dynamic/json?label=citation&style=social&logo=googlescholar&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F61ea0a87eab0029de9f4f6032108cb8d94cca3ac%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/Inducing-High-Energy-Latency-of-Large-Models-with-Gao-Bai/61ea0a87eab0029de9f4f6032108cb8d94cca3ac) [![GitHub Repo stars](https://img.shields.io/github/stars/KuofengGao/Verbose_Images)](https://github.com/KuofengGao/Verbose_Images) 





<iframe src="https://arxiv.org/pdf/2401.11170" width="100%" height="600px" style="border: none;">
This browser does not support PDFs
</iframe>


## è®ºæ–‡æ€ç»´å¯¼å›¾

<div class="card file-block" markdown="1">
<div class="file-icon"><img src="/style/images/xmind.svg" style="height: 3em;"></div>
<div class="file-body">
<div class="file-title">è®ºæ–‡è§£ææ ‘</div>
<div class="file-meta">132KB / 2025-08-03</div>
</div>
<a class="down-button" target="_blank" href="VerboseImages.xmind" markdown="1">:fontawesome-solid-download: ä¸‹è½½</a>
</div>

ICLR å¥½å¤šå®éªŒå•Šã€ã€

![VerboseImages](assets/VerboseImages.assets/VerboseImages.webp)

## è®ºæ–‡ç¬”è®°

### previous

NICGSlowDownä¸è¡Œçš„åŸå› 

- failure case: image-language model
- train for lstm&cnn&rnn not VLM
- VLMå¯¹äºåŒä¸€ä¸ªè¾“å…¥ï¼Œè¾“å‡ºä¹Ÿå¯èƒ½ä¸åŒï¼ˆsampling policiesï¼‰ï¼›ä½†æ˜¯NICGSlowDown ä¼˜åŒ–ç‰¹å®šè¾“å‡ºtokençš„å¯¹ç‡





![image-20250804214551732](assets/VerboseImages.assets/image-20250804214551732.webp)

æ€»çš„loss functionä¸º

$$
\min_{\boldsymbol{x}^{\prime}}\lambda_1\times\mathcal{L}_1(\boldsymbol{x}^{\prime})+\lambda_2\times\mathcal{L}_2(\boldsymbol{x}^{\prime})+\lambda_3\times\mathcal{L}_3(\boldsymbol{x}^{\prime}),\quad s.t.\left||\boldsymbol{x}^{\prime}-\boldsymbol{x}|\right|_p\leq\epsilon
$$


### $\mathcal{L}_1$ - delayed EOS loss 

$$
\mathcal{L}_1(\boldsymbol{x}^{\prime})=\frac{1}{N}\sum_{i=1}^Nf_i^\mathrm{EOS}\left(\boldsymbol{x}^{\prime}\right)
$$

å› ä¸ºä¸çŸ¥é“ä»€ä¹ˆæ—¶å€™ç»“æŸï¼Œæ‰€ä»¥ä¼˜åŒ–æ‰€æœ‰ä½ç½®ä¸ŠEOSçš„æ¦‚ç‡

### $\mathcal{L}_2$ - Enhancing output uncertainty 

$$
\mathcal{L}_2(\boldsymbol{x}^{\prime})=\sum_{i=1}^ND_{\mathrm{KL}}\left(f_i\left(\boldsymbol{x}^{\prime}\right),\mathcal{U}\right)
$$

### $\mathcal{L}_3$ - Improving token diversity 

- $[g_1(x'),g_2(x'), \cdots g_n(x')]$ è¡¨ç¤ºæ‰€æœ‰ç”Ÿæˆçš„tokençš„éšè—çŠ¶æ€çš„æ‹¼æ¥çŸ©é˜µï¼Œ**å¢åŠ éšè—çŠ¶æ€çŸ©é˜µçš„ç§©**ä¼šå¾—åˆ° **æ›´å¤šæ ·åŒ–çš„tokenéšè—çŠ¶æ€** ã€‚
- ç”±äºç§©ä¼˜åŒ–å›°éš¾ï¼Œä½¿ç”¨ **æ ¸èŒƒæ•°(nuclear norm)ä½œä¸ºè¿‘ä¼¼** ï¼Œå¹¶å®šä¹‰äº†ç›¸åº”çš„ **tokenå¤šæ ·æ€§æŸå¤±å‡½æ•°** 
  
$$
\mathcal{L}_3(\boldsymbol{x}^\prime)=-||[g_1(\boldsymbol{x}^\prime);g_2(\boldsymbol{x}^\prime);\cdots;g_N(\boldsymbol{x}^\prime)]||_*
$$


é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­é—´æ¥ä¿ƒè¿›tokençš„å¤šæ ·æ€§ï¼Œä»è€Œå®ç°å¢åŠ èƒ½é‡å’Œå»¶è¿Ÿæˆæœ¬çš„ç›®æ ‡ã€‚




### trick1 - PGD

an iterative optimization technique that updates the solution by taking steps in the direction of the negative gradient while projecting the result back onto the feasible set

### trick2 $\lambda,m$ - temporal weight adjustment algorithm

**æ—¶é—´æƒé‡è°ƒæ•´ç®—æ³•**


$$
\begin{aligned}&\lambda_1(t)=||\mathcal{L}_2(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:||\mathcal{L}_1(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:\mathcal{T}_1(t),\\&\lambda_2(t)=||\mathcal{L}_2(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:||\mathcal{L}_2(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:\mathcal{T}_2(t),\\&\lambda_3(t)=||\mathcal{L}_2(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:||\mathcal{L}_3(\boldsymbol{x}_{t-1}^{\prime})||_1\:/\:\mathcal{T}_3(t)
\end{aligned}
$$

temporal decay functions are set as:

$$
\mathcal{T}_1(t)=a_1\times\ln(t)+b_1\\
\mathcal{T}_2(t)=a_2\times\ln(t)+b_2\\
\mathcal{T}_3(t)=a_3\times\ln(t)+b_3
$$

æ­¤å¤–ï¼Œå¼•å…¥åŠ¨é‡å€¼ m åˆ°æƒé‡çš„æ›´æ–°è¿‡ç¨‹ä¸­



### è¯„ä»·1 -  GradCAM

a gradient-based visualization technique that generates attention maps highlighting the relevant regions in the input images

![image-20250804220529126](assets/VerboseImages.assets/image-20250804220529126.webp)

### è¯„ä»·2 - CHAIR

**CHAIRï¼ˆCaption Hallucination Assessment with Image Relevanceï¼‰** æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°**å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹**ä¸­**å¹»è§‰ç°è±¡**çš„æŒ‡æ ‡ã€‚


- **å›¾åƒæè¿°ç”Ÿæˆä»»åŠ¡**è¦æ±‚æ¨¡å‹æ ¹æ®è¾“å…¥å›¾åƒç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ã€‚ç„¶è€Œï¼Œæ¨¡å‹æœ‰æ—¶ä¼šç”Ÿæˆ**ä¸å›¾åƒå†…å®¹ä¸ç¬¦**çš„æè¿°ï¼Œå³**å¹»è§‰ç°è±¡**ã€‚


$CHAIR_i$ - Instance-level CHAIRï¼Œåæ˜ äº†æ¨¡å‹åœ¨**å®ä¾‹çº§åˆ«**ä¸Šçš„å¹»è§‰ç¨‹åº¦

$$
CHAIR_i = \frac{\text{å¹»è§‰å¯¹è±¡å®ä¾‹çš„æ•°é‡}}{\text{æ€»å¯¹è±¡å®ä¾‹çš„æ•°é‡}}
$$

$CHAIR_s$ - Sentence-level CHAIR

$$
CHAIR_s = \frac{\text{åŒ…å«å¹»è§‰å¯¹è±¡çš„å¥å­æ•°é‡}}{\text{æ€»å¥å­æ•°é‡}}
$$





## ä»£ç å¤ç° - éƒ¨åˆ†ç»“æœ


### first trial

```
2025-08-02 01:45:22,698 - OPT - INFO - PARAMETER ...
2025-08-02 01:45:22,699 - OPT - INFO - Namespace(epsilon=0.032, step_size=0.0039, iter=100, gpu=0, seed=256, root_path='/root/autodl-tmp/Capstone/Verbose_Images', dataset='/root/autodl-tmp/Capstone/Verbose_Images/dataset')
2025-08-02 01:48:57,167 - OPT - INFO - Original sequences: layers of tall buildings
2025-08-02 01:48:57,168 - OPT - INFO - Verbose sequences: the last essex community bus service has left the network
2025-08-02 01:48:57,168 - OPT - INFO - ------------------------
2025-08-02 01:48:57,168 - OPT - INFO - Original sequences: a city bus moving down a road with another bus behind it
2025-08-02 01:48:57,168 - OPT - INFO - Verbose sequences: â€™2149qb bfti grnt 45 hp twin barrier tri dup plasma plus interurbia 82 leadless all colour with rainbow rainbow stock clips from the blue and rainbow sofa where can i buy a sofa in india, search blue sofa in india, person, indian sofa, couch, city bus, transportation, in the city, the city bus, orlando bus, electric bus, metro bus, metro system, regional bus, ftl buses, metros, btm, btdl
2025-08-02 01:48:57,168 - OPT - INFO - ------------------------
2025-08-02 01:48:57,168 - OPT - INFO - Original sequences: a purple bus sitting next to some buildings
2025-08-02 01:48:57,168 - OPT - INFO - Verbose sequences: the purple bus is driving on the street
2025-08-02 01:48:57,168 - OPT - INFO - ------------------------
2025-08-02 01:48:57,168 - OPT - INFO - Original images, Length: 8.00, Energy: 14.31, Latency: 0.34
2025-08-02 01:48:57,168 - OPT - INFO - Verbose images, Length: 28.67, Energy: 90.84, Latency: 0.91
```





![image-20250804220104948](assets/VerboseImages.assets/image-20250804220104948.webp)



### Distribution

![image-20250804220116470](assets/VerboseImages.assets/image-20250804220116470.webp)

### Chair

![image-20250804220134095](assets/VerboseImages.assets/image-20250804220134095.webp)



### ablation Exp

![image-20250804220331424](assets/VerboseImages.assets/image-20250804220331424.webp)





### é»‘ç›’æ”»å‡»

![image-20250804220405115](assets/VerboseImages.assets/image-20250804220405115.webp)

### å…¶ä»–ä»»åŠ¡

![image-20250804220423481](assets/VerboseImages.assets/image-20250804220423481.webp)









## ä»£ç å¤ç° - å‡†å¤‡å·¥ä½œ

### æœåŠ¡å™¨

AudoDL çš„ RTX 3090


```bash title="å­¦æœ¯èµ„æºåŠ é€Ÿ"
source /etc/network_turbo
```

!!! note "è®ºæ–‡ä¸­ç”¨çš„æ˜¯A100 40GB"





### æ¨¡å‹

| Name         |                               |      |      |
| ------------ | ----------------------------- | ---- | ---- |
| BLIP         | encoder-decoder model in 224M |      |      |
| BLIP-2       | OPT-2.7B LM                   |      |      |
| InstructBLIP | Vicuna-7B LM                  |      |      |
| MiniGPT-4    | Vicuna-7B LM                  |      |      |

### Metrics

using NVIDIA Management Library (NVML)

- energy consumption
- latency time
- the length of generated sequences
- response time cost





### æ•°æ®é›†ä¸‹è½½


ä¸‹è½½cocoæ•°æ®é›†[COCO - Common Objects in Context](https://cocodataset.org/#download)


### æ•°æ®é›†å‡†å¤‡


```python title="å–å‡ºéšæœºå›¾ç‰‡"
import os
import random
import shutilh

def random_select_images(source_folder, target_folder, num_images=1000):
    """
    ä»æºæ–‡ä»¶å¤¹éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„å›¾ç‰‡åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
    
    å‚æ•°:
        source_folder: æºå›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
        num_images: è¦é€‰æ‹©çš„å›¾ç‰‡æ•°é‡(é»˜è®¤1000)
    """
    # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(target_folder, exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    all_images = [f for f in os.listdir(source_folder) 
                 if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå›¾ç‰‡
    if len(all_images) < num_images:
        raise ValueError(f"æ–‡ä»¶å¤¹ä¸­åªæœ‰ {len(all_images)} å¼ å›¾ç‰‡ï¼Œä¸è¶³ {num_images} å¼ ")
    
    # éšæœºé€‰æ‹©
    selected_images = random.sample(all_images, num_images)
    
    # å¤åˆ¶åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
    for img in selected_images:
        src_path = os.path.join(source_folder, img)
        dst_path = os.path.join(target_folder, img)
        shutil.copy2(src_path, dst_path)
    
    print(f"æˆåŠŸå¤åˆ¶ {len(selected_images)} å¼ å›¾ç‰‡åˆ° {target_folder}")

# ä½¿ç”¨ç¤ºä¾‹
source = "/root/autodl-tmp/train2017"  # æ›¿æ¢ä¸ºä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
target = "/Capstone/Verbose_Images/dataset"       # æ›¿æ¢ä¸ºè¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
random_select_images(source, target, 1000)
```




## ä»£ç å¤ç° - é—®é¢˜è§£å†³

!!! note "è¿™ç¯‡ä½œè€…å…¶å®æ²¡æœ‰æŠŠæ‰€æœ‰çš„ä»£ç æ”¾å‡ºæ¥ï¼Œåªæ”¾äº†ç®—æ³•éƒ¨åˆ†çš„demoï¼Œæ‰€ä»¥æƒ³è¦å¤ç°æ‰€æœ‰setçš„è¯ï¼Œéœ€è¦èŠ±è´¹ä¸€å®šæ—¶é—´ã€‚æ„Ÿè§‰ä½œè€…ä¸æ˜¯å¾ˆåšé“å•Šxs"

### uvå®‰è£…

```shell
uv env --python=3.9.2
```

```shell
uv pip install -r requirements.txt
```


åº“å½“ä¸­çš„requirement.txtä¸èƒ½ç›´æ¥ä½¿ç”¨ï¼Œæ‰€ä»¥æˆ‘è§£å†³äº†ä¸€äº›é—®é¢˜ï¼Œç„¶åè®°å½•åœ¨äº†ä¸‹é¢

??? note "ä¿®æ”¹ç‰ˆæœ¬"

    ```txt title="requirement.txt"
    accelerate==1.9.0
    addict==2.4.0
    altair==5.5.0
    antlr4-python3-runtime==4.9.3
    asttokens==3.0.0
    attrs==25.3.0
    bitsandbytes==0.37.0
    bleach==6.2.0
    blinker==1.9.0
    blis==0.7.11
    braceexpand==0.1.7
    cachetools==6.1.0
    catalogue==2.0.10
    certifi==2025.7.14
    cffi==1.17.1
    cfgv==3.4.0
    charset-normalizer==3.4.2
    click==8.1.8
    comm==0.2.3
    confection==0.1.5
    configargparse==1.7.1
    contexttimer==0.3.3
    contourpy==1.3.0
    cycler==0.12.1
    cymem==2.0.11
    dash==3.2.0
    decorator==5.2.1
    decord==0.6.0
    diffusers==0.16.0
    distlib==0.4.0
    easydict==1.9
    einops==0.8.1
    eval-type-backport==0.2.2
    exceptiongroup==1.3.0
    executing==2.2.0
    fairscale==0.4.4
    fastjsonschema==2.21.1
    filelock==3.18.0
    flask==2.1.3
    fonttools==4.59.0
    fsspec==2025.7.0
    ftfy==6.3.1
    gitdb==4.0.12
    gitpython==3.1.45
    h5py==3.14.0
    huggingface-hub==0.25.2
    identify==2.6.12
    idna==3.10
    imageio==2.37.0
    imageio-ffmpeg==0.6.0
    importlib-metadata==8.7.0
    importlib-resources==6.5.2
    iopath==0.1.10
    ipython==8.18.1
    ipywidgets==8.1.7
    itsdangerous==2.2.0
    jedi==0.19.2
    jinja2==3.1.6
    joblib==1.5.1
    jsonschema==4.25.0
    jsonschema-specifications==2025.4.1
    jupyter-core==5.8.1
    jupyterlab-widgets==3.0.15
    kaggle==1.7.4.5
    kiwisolver==1.4.7
    langcodes==3.5.0
    language-data==1.3.0
    lazy-loader==0.4
    marisa-trie==1.2.1
    markupsafe==2.0.1
    matplotlib==3.9.4
    matplotlib-inline==0.1.7
    moviepy==2.2.1
    mpmath==1.3.0
    murmurhash==1.0.13
    narwhals==2.0.1
    nbformat==5.5.0
    nest-asyncio==1.6.0
    networkx==3.2.1
    nltk==3.9.1
    nodeenv==1.9.1
    numpy==1.26.4
    nvidia-cublas-cu12==12.6.4.1
    nvidia-cuda-cupti-cu12==12.6.80
    nvidia-cuda-nvrtc-cu12==12.6.77
    nvidia-cuda-runtime-cu12==12.6.77
    nvidia-cudnn-cu12==9.5.1.17
    nvidia-cufft-cu12==11.3.0.4
    nvidia-cufile-cu12==1.11.1.6
    nvidia-curand-cu12==10.3.7.77
    nvidia-cusolver-cu12==11.7.1.2
    nvidia-cusparse-cu12==12.5.4.2
    nvidia-cusparselt-cu12==0.6.3
    nvidia-ml-py==12.575.51
    nvidia-nccl-cu12==2.26.2
    nvidia-nvjitlink-cu12==12.6.85
    nvidia-nvtx-cu12==12.6.77
    omegaconf==2.3.0
    open3d==0.16.0
    opencv-python-headless==4.5.5.64
    opendatasets==0.1.22
    packaging==25.0
    pandas==2.3.1
    parso==0.8.4
    pathlib-abc==0.1.1
    pathy==0.11.0
    peft==0.10.0
    pexpect==4.9.0
    pillow==11.3.0
    platformdirs==4.3.8
    plotly==6.2.0
    portalocker==3.2.0
    pre-commit==4.2.0
    preshed==3.0.10
    proglog==0.1.12
    prompt-toolkit==3.0.51
    protobuf==6.31.1
    psutil==7.0.0
    ptyprocess==0.7.0
    pure-eval==0.2.3
    pyarrow==21.0.0
    pycocoevalcap==1.2
    pycocotools==2.0.10
    pycparser==2.22
    pydantic==1.10.22
    pydeck==0.9.1
    pygments==2.19.2
    pynvml==12.0.0
    pyparsing==3.2.3
    pyquaternion==0.9.9
    pyrapl==0.2.3.1
    python-dateutil==2.9.0.post0
    python-dotenv==1.1.1
    python-magic==0.4.27
    python-slugify==8.0.4
    pytz==2025.2
    pyyaml==6.0.2
    pyyaml-env-tag==0.1
    referencing==0.36.2
    regex==2025.7.33
    requests==2.32.4
    retrying==1.4.1
    rpds-py==0.26.0
    safetensors==0.5.3
    scikit-image==0.24.0
    scikit-learn==1.6.1
    scipy==1.13.1
    sentencepiece==0.2.0
    sentry-sdk==2.34.1
    setuptools==80.9.0
    six==1.17.0
    smart-open==6.4.0
    smmap==5.0.2
    soundfile==0.13.1
    spacy==3.6.0
    spacy-legacy==3.0.12
    spacy-loggers==1.0.5
    srsly==2.5.1
    stack-data==0.6.3
    streamlit==1.47.1
    sympy==1.14.0
    tenacity==9.1.2
    text-unidecode==1.3
    thinc==8.1.8
    threadpoolctl==3.6.0
    tifffile==2024.8.30
    timm==0.4.12
    tokenizers==0.13.3
    toml==0.10.2
    torch==2.7.1
    torchaudio==2.7.1
    torchvision==0.22.1
    tornado==6.5.1
    tqdm==4.67.1
    traitlets==5.14.3
    transformers==4.31.0
    triton==3.3.1
    typer==0.9.4
    typing-extensions==4.14.1
    tzdata==2025.2
    urllib3==2.5.0
    virtualenv==20.32.0
    wandb==0.21.0
    wasabi==1.1.3
    watchdog==6.0.0
    wcwidth==0.2.13
    webdataset==0.2.100
    webencodings==0.5.1
    werkzeug==2.1.2
    wheel==0.45.1
    widgetsnbextension==4.0.14
    zipp==3.23.0
    ```



### condaå®‰è£…

ä¹Ÿå¯ä»¥ä½¿ç”¨conda è¿›è¡Œå®‰è£…
```bash
conda create -n VI python=3.9.2
```
Then, activate the environment:
```bash
conda activate VI
```

Install requirements:
```bash
pip install -e .
```



### logå‡½æ•°ä¸èƒ½ç”¨

```python
from scipy import log
log(x)
```

è¿™å¥è¯ç”¨ä¸äº†ï¼Œæ‰€ä»¥æ”¹æˆäº†

```python
import numpy as np
ratio1 = 10.0 * np.log(tdx + 1) - 20.0
ratio2 = 0.5 * np.log(tdx + 1) + 1.0
```

1.61æ˜¯æœ‰logå‡½æ•°çš„ï¼Œ[log â€” SciPy v1.16.0 æ‰‹å†Œ - SciPy ç§‘å­¦è®¡ç®—åº“](https://docs.scipy.org.cn/doc/scipy/reference/generated/scipy.stats.log.html)

ä½†æ˜¯ä½¿ç”¨çš„æ˜¯python3.9 æœ€é«˜1.31.1ï¼Œæ‰€ä»¥åªèƒ½æ›´æ¢å…¶ä»–æ–¹æ³•
### moviepyåº“
`audio_processors.py`æ–‡ä»¶ä¸­

```python title="é”™è¯¯å¯¼å…¥"
from moviepy.editor import VideoFileClip
```
> No module named 'moviepy.editor'è§£å†³æ–¹æ³•

æ­£ç¡®å¯¼å…¥åº”è¯¥æ˜¯
```python
#æå–mp4è§†é¢‘é‡Œçš„éŸ³é¢‘ä¿å­˜ä¸ºmp3.py
from moviepy.video.io.VideoFileClip import VideoFileClip
```

### BERTæ¨¡å‹åŠ è½½

è¿™é‡Œå› ä¸ºautodlçš„ç½‘ç»œé—®é¢˜ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è‡ªå·±ä¸‹è½½ä¸€ä¸‹pretrainedçš„è¿™ä¸ªbert(å› ä¸ºautodlå·²ç»ä¸‹è½½è¿‡äº†ç›¸å½“äº, åœ¨`/root/autodl-pub/BERT-Pretrain-Modelbert-base-uncased.zip`ä¸­)
```python
def init_tokenizer(cls, truncation_side="right"):
        tokenizer = BertTokenizer.from_pretrained("models/bert-base-uncased", truncation_side=truncation_side)
        tokenizer.add_special_tokens({"bos_token": "[DEC]"})
        return tokenizer
```


### datasetå‚æ•°å’Œrootpathå‚æ•°è§£æ

```python 
def parse_args():
    '''PARAMETERS'''
    parser = argparse.ArgumentParser('generate verbose images')
    parser.add_argument('--epsilon', type=float, default=0.032, help='the perturbation magnitude')
    parser.add_argument('--step_size', type=float, default=0.0039, help='the step size')
    parser.add_argument('--iter', type=int, default=1000, help='the iteration')
    parser.add_argument('--gpu', type=int, default=0, help='GPU index')
    parser.add_argument('--seed', type=int, default=256, help='random seed')
    # å¢åŠ ä¸¤è¡Œ
    parser.add_argument('--root_path', type=str, default='.', 
                      help='Root directory')
    parser.add_argument('--dataset', type=str, required=True,
                      help='Dataset name')
```

### åº“ç‰ˆæœ¬é—®é¢˜ä¿®æ­£

**open3dåº“**
> ERROR: No matching distribution found for open3d==0.13.0
åˆ¶å®šç‰ˆæœ¬ä¸è¡Œå°±è®©ç®¡ç†å™¨è‡ªå·±å¤„ç†

```bash
pip install open3d
```


**numpyä¸spacyåº“**
> cannot import name 'log' from 'scipy'

è¿™é‡Œè¿™ä¸‰ä¸ªåŒ…çš„ç‰ˆæœ¬éœ€è¦ç‰¹æ®Šå¤„ç†ä¸€ä¸‹ï¼Œè¿™é‡Œæ²¿ç”¨æˆ‘ä¹‹å‰åœ¨å¦ä¸€ä¸ªé¡¹ç›®é…ç½®çš„ã€‚

å³`numpy==1.26.4`ï¼Œ`spacy==3.6.0`

åˆå› ä¸ºthinc released 8.3.0 with a depenÂ·dency on numpy 2ï¼Œå¦‚æœè¦ä½¿ç”¨numpy=1.*ï¼Œå°±éœ€è¦å®‰è£…`thinc<8.3.0`

```shell
pip install -U spacy==3.6.0
pip install numpy==1.26.4
pip install thinc==8.1.8
```

**peftä¸transformersåº“**

> ImportError: cannot import name 'Cache' from 'transformers' (/root/miniconda3/envs/VI/lib/python3.9/site-packages/transformers/__init__.py)

```
pip install peft==0.10.0
pip install transformers==4.31.0
```

[cannot import name '_expand_mask' Â· Issue #571 Â· salesforce/LAVIS](https://github.com/salesforce/LAVIS/issues/571)



**huggingface_hubåº“**

>ImportError: cannot import name 'cached_download' from 'huggingface_hub' (/root/miniconda3/envs/VI/lib/python3.9/site-packages/huggingface_hub/__init__.py)

åŸå› ï¼šåœ¨huggingface_hub 0.26 ä¸­ç§»é™¤äº†å¦‚ä¸‹å‡½æ•°ï¼Œ[åŸé“¾æ¥](https://github.com/huggingface/huggingface_hub/pull/2579)

```shell
pip install huggingface_hub==0.25.2 -i https://pypi.tuna.tsinghua.edu.cn/simple
```


### 

```
vi lavis/configs/models/blip2/blip2_instruct_vicuna7b.yaml
```

```yml title "ä¿®æ”¹æˆä¸‹é¢çš„æ ·å­"
llm_model: "lmsys/vicuna-7b-v1.5"
```





### å…¶ä»–é—®é¢˜-å†…å­˜ä¸å¤Ÿ

[script got killed while running Â· Issue #2 Â· KuofengGao/Verbose_Images](https://github.com/KuofengGao/Verbose_Images/issues/2)

ä½†æˆ‘è¿˜æ²¡æœ‰é‡åˆ°è¿™ä¸ªé—®é¢˜



