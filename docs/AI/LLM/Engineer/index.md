# The LLM Engineer Roadmap



converting text into numbers through tokenization, processing these tokens through layers including attention mechanisms, and finally generating new text through various sampling strategies.
## 1. Running LLMs
- LLM APIs
- Open-source LLMs
- Prompt engineering
- Structuring outputs

## 2. Building a Vector Storage
- Ingesting documents
- Splitting documents
- Embedding models
- Vector databases


## 3. Retrieval Augmented Generation

- Orchestrators
- Retrievers
- Memory
- Evaluation


## 4. Advanced RAG
- Query construction
- Agents and tools
- Post-processing
- Program LLMs

## 5. Agents

- Agent fundamentals
- Agent frameworks
- Multi-agents

## 6. Inference optimization

- Flash Attention
- Key-value cache
- Speculative decoding

## 7. Deploying LLMs

- Local deployment
- Demo deployment
- Server deployment
- Edge deployment


## 8. Securing LLMs

- Prompt hacking
- Backdoors
- Defensive measures