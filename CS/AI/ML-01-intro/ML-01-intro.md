# 01 | æœºå™¨å­¦ä¹ å¯¼è®º

!!! note "è¯¾ç¨‹ä¿¡æ¯"
    === "æœºå™¨å­¦ä¹ "
        - è¯¾ç¨‹æ—¶é—´ï¼š2024å¹´ç§‹å†¬
        - è¯¾ç¨‹æ•™å¸ˆï¼šèµµæ´²
        - è€ƒæ ¸å†…å®¹ï¼š2æ¬¡ä¹¦é¢ä½œä¸š+2æ¬¡ç¼–ç¨‹ä½œä¸š[Kaggle](https://www.kaggle.com/)ï¼ˆ45%ï¼‰+15æ¬¡éšæœºç­¾åˆ°ï¼ˆ15%ï¼‰+1æ¬¡æœŸæœ«æ‘¸åº•è€ƒè¯•+1æ¬¡æœŸæœ«è€ƒè¯•ï¼›ï¼ˆ40%ï¼‰
        - è¯¾æœ¬ï¼šè¥¿ç“œä¹¦
    === "å®ç”¨çš„æœºå™¨å­¦ä¹ "

    === "äººå·¥æ™ºèƒ½ä¸å®‰å…¨"
        - è¯¾ç¨‹æ—¶é—´ï¼š2024å¹´ç§‹å†¬
        - è¯¾ç¨‹æ•™å¸ˆï¼šé™ˆè‰³å§£
        - workloadï¼š


Artificial Intelligence is a scientific field concerned with the development of algorithms that allow computers to learn without being explicitly programmed

â€¢ Machine Learning is a branch of Artificial Intelligence, which focuses on
methods that learn from data and make predictions on unseen data

[äººå·¥æ™ºèƒ½åŸºç¡€ - é¹¤ç¿”ä¸‡é‡Œçš„ç¬”è®°æœ¬ (tonycrane.cc)](https://note.tonycrane.cc/cs/ai/basic/)

[02ï¼šè´å¶æ–¯å®šç† - å°è§’é¾™çš„å­¦ä¹ è®°å½• (zhang-each.github.io)](https://zhang-each.github.io/My-CS-Notebook/ML/ç»Ÿè®¡æœºå™¨å­¦ä¹ 02ï¼šè´å¶æ–¯å®šç†/)

[å‘½é¢˜é€»è¾‘ - Jerry's Blog (wxxcl.tech)](https://blog.wxxcl.tech/course/aid/çŸ¥è¯†è¡¨è¾¾ä¸æ¨ç†/å‘½é¢˜é€»è¾‘/)

[ç¬”è®°](https://github.com/mura1n/Machine-Learning-in-Practice-Crash-Course-Notes)

## å¯¼è®º

!!! note "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
    ä»¥æ•°æ®ä½œä¸ºç»éªŒçš„è½½ä½“ï¼Œåˆ©ç”¨ç»éªŒæ•°æ®ä¸æ–­æé«˜æ€§èƒ½çš„è®¡ç®—æœºç³»ç»Ÿ/ç¨‹åº/ç®—æ³•

    æœ€ç†æƒ³çš„æœºå™¨å­¦ä¹ æŠ€æœ¯æ˜¯å­¦ä¹ åˆ° **æ¦‚å¿µ** ï¼ˆâ¼ˆç±»å­¦ä¹ ï¼Œå¯ç†è§£çš„ï¼‰

- supervised learning ï¼šåˆ†ç±»ä»»åŠ¡ï¼ˆç¦»æ•£ï¼‰ï¼Œå›å½’ä»»åŠ¡ï¼ˆè¿ç»­ï¼‰ï¼›å­¦ä¹ ä¸€ä¸ªæ˜ å°„å‡½æ•°$x\rightarrow \mathbf{y}$
- unsupervised learning ï¼šæ‰¾åˆ°æ ‡ç­¾æˆ–è€…æ¨¡å¼ï¼Œèšç±»ã€é™ç»´
- reinforcement learningï¼šå¼ºåŒ–å­¦ä¹ ï¼ˆç›¸å½“äºæ˜¯ç›‘ç£å­¦ä¹ ï¼‰
  ![image-20240611173113321](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/image-20240611173113321.png)



PAC æ¨¡å‹

$$
P(|f(x)-y \le \epsilon|) \ge 1-\delta
$$

é¢„æµ‹è¯¯å·®å¾ˆå°çš„æ¦‚ç‡å¤§äº1-Î´

iid ä¿è¯äº†ç»Ÿè®¡æ„ä¹‰ä¸Šå¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ 

è€Œ$\epsilon$ è¡¨ç¤ºäº†æ³›åŒ–èƒ½åŠ›

æ¦‚ç‡è¿‘ä¼¼æ­£ç¡®ï¼šä»¥å¾ˆé«˜çš„æ¦‚ç‡å¾—åˆ°ä¸€ä¸ªå¾ˆæ¥è¿‘çœŸå®å€¼çš„ç»“æœ

??? note "Fundamental Concepts in Machine Learning"

    === "**Sample, Instance, Example**"
        - Sample, instance, and example refer to the same concept, which is a single data point used for training or testing a machine learning model.
        - instance don't contain the label
        - example: instace + label

    === "**Feature, Representation, Predictor**"
        - A feature is an attribute or aspect of the data used to describe a data point.
        - Representation refers to the process of converting data into a form that a computer can process, such as a vector or a matrix.
        - A predictor is a model or function used to predict the target variable.
    
    === "**Label, Target, Class, Pattern Class**"
    
        - A label is the true category or value of the data, used in supervised learning.
        - A target is the variable that the model is intended to predict.
        - A pattern class is a category or grouping of data.
        - A class is a group of data points that belong to the same pattern.
    
    === "**Training Data**"
    
        - Training data is the dataset used to train the model.
        - $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$ represent individual data points in the training data, where $x_i$ is the feature and $y_i$ is the label.
    
    === "**Model, Classifier, Regressor**"
    
        - A model is a mathematical structure used to describe data or predict the target.
        - A classifier is a model used for categorizing data, with a discrete output representing the category.
        - A regressor is a model used for regression analysis, with a continuous output representing the numerical value.
    
    === "**Test Data**"
    
        - Test data is the dataset used to evaluate the performance of the model.
        - $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$ represent individual data points in the test data, where $x_i$ is the feature and $y_i$ is the label.
    
    === "éªŒè¯é›†"
        è®­ç»ƒé›†ä¸Šç”¨æ¥è°ƒå‚æ•°çš„é›†åˆ

|æœºå™¨å­¦ä¹ æœ¯è¯­|ç–¾ç—…è¯Šæ–­ä¾‹å­|
|---|---|
|æ•°æ®é›†ï¼Œç‰¹å¾ï¼Œæ ‡è®°|æŸç–¾ç—…æ‚£è€…â¼ˆç¾¤|
|å‡è®¾ç©ºé—´|æ‰€æœ‰å¯èƒ½çš„è¯|
|ç‰ˆæœ¬ç©ºé—´ï¼ˆè·Ÿè®­ç»ƒé›†ä¸€è‡´çš„â€œå‡è®¾é›†åˆâ€ï¼‰|èƒ½æ²»å¥½çš„è¯|
|å½’çº³åæ‰§|åæ‰§ï¼šä¸­è¯è¥¿è¯ï¼Œå‰¯ä½œç”¨å¤§å°ï¼Œè´¹ç”¨é«˜ä½|
|æ²¡æœ‰å…è´¹åˆé¤|æ²¡æœ‰ç‰¹æ•ˆè¯ï¼Œä¸‡èƒ½è¯|


**inductive bias** | å½’çº³åå¥½: æœºå™¨å­¦ä¹ ç®—æ³•å¯¹äºæŸäº›å‡è®¾çš„å€¾å‘æ€§ï¼Œå­˜åœ¨å¤šæ¡æ›²çº¿ç¬¦åˆæ•°æ®æ—¶å€™ï¼Œç®—æ³•çš„å€¾å‘æ€§å«åšinductive bias

**Occam's Razor** | å¥¥å¡å§†å‰ƒåˆ€åŸç†ï¼šåœ¨æ‰€æœ‰å¯èƒ½çš„è§£é‡Šä¸­ï¼Œæœ€ç®€å•çš„è§£é‡Šæœ€æœ‰å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼ˆå¤§é“è‡³ç®€ï¼‰

!!! tip "ç®—æ³•çš„ä¼˜è¶Šæ€§æ¥è‡ªäºç®—æ³•çš„assumptionå’Œæ•°æ®çš„åŒ¹é…ç¨‹åº¦"

**No Free Lunch Theorem**:
ä¸€ä¸ªç®—æ³•Aåœ¨æŸä¸ªé—®é¢˜ä¸Šè¡¨ç°æ¯”Bå¥½ï¼Œæ¯”å­˜åœ¨å¦ä¸€ä¸ªé—®é¢˜ï¼ŒBæ¯”Aå¥½
è„±ç¦»å…·ä½“é—®é¢˜ï¼Œç©ºæ³›è°ˆè®ºâ€œä»€ä¹ˆå­¦ä¹ ç®—æ³•æ›´å¥½â€æ¯«æ— æ„ä¹‰

è„±ç¦»æ•°æ®åˆ†å¸ƒå’Œè¾“å‡ºå»è°ˆå­¦ä¹ ç®—æ³•ï¼Œæ˜¯æ²¡æœ‰æ„ä¹‰çš„

[NFLå®šç†æ¨å¯¼-CSDNåšå®¢](https://blog.csdn.net/qq_43246110/article/details/104617780)
### ä»€ä¹ˆæ—¶å€™ä½¿ç”¨æœºå™¨å­¦ä¹ 

**there should be some patterns in the data**

- we know the patterns,but don't know how to use
- ML can discover the pattern themselves

æœºå™¨å­¦ä¹ æ˜¯å¤§èƒ†å‡è®¾å’Œå°å¿ƒæ±‚è¯çš„æŠ˜è¡·




### pipeline

pipelineï¼Œä¸­æ–‡æ„ä¸ºç®¡çº¿ï¼Œæ„ä¹‰ç­‰åŒäºæµæ°´çº¿ã€‚åœŸå‘³ä¸€ç‚¹ ä½ æŠŠå®ƒ ç¿»è¯‘æˆ **ä¸€æ¡é¾™æœåŠ¡**ï¼›ä¸“ä¸šä¸€ç‚¹ï¼Œå«å®ƒ **ç»¼åˆè§£å†³æ–¹æ¡ˆ**<br>

![image-20240614191015217](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/image-20240614191015217.png)

- **å®šä¹‰é—®é¢˜**:æ˜¯æœ‰ç›‘ç£è¿˜æ˜¯æ— ç›‘ç£ï¼Ÿæ˜¯åˆ†ç±»è¿˜æ˜¯å›å½’ï¼Ÿ
- æ”¶é›†æ•°æ®ï¼š
- æ•°æ®é¢„å¤„ç† transform data & get featuresï¼šæ‰¾åˆ°xå’Œy
- åˆ›å»ºæ¨¡å‹ï¼ˆå…·ä½“åˆ°æ¨¡å‹ä¹Ÿæœ‰ç›¸åº”çš„Pipeline,æ¯”å¦‚æ¨¡å‹çš„å…·ä½“æ„æˆéƒ¨åˆ†ï¼šæ¯”å¦‚GCN+Attention+MLPçš„æ··åˆæ¨¡å‹ï¼‰
- è¯„ä¼°æ¨¡å‹ç»“æœ
- æ¨¡å‹è°ƒå‚

æ˜¯ä¸€ä¸ª**è¿­ä»£**çš„è¿‡ç¨‹

### generalization æ³›åŒ–
æœºå™¨å­¦ä¹ æœ€é‡è¦çš„èƒ½åŠ›å°±æ˜¯generalizationï¼Œæœ€é‡è¦çš„å°±æ˜¯è¦å­¦ä¹ åˆ°ä¸€äº›æ¦‚å¿µ

## æ€§èƒ½
$ç»éªŒæ€§èƒ½E \approx æ³›åŒ–æ€§èƒ½E^*$

iidå‡è®¾ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ `identical and independently distributed`

### å®šä¹‰
"**Training Error and Test Error**"
- Training error is the error alculated on the training data.
- Test error is the error calculated on the test data.

use test error to evaluate the quality of model
<img src="https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/image-20240614191634130.png" alt="image-20240614191634130" style="zoom: 50%;" />

!!! tip "ä¸åŒçš„ç®—æ³•å°±æ˜¯åœ¨ç”¨ä¸åŒçš„æ–¹å¼å»è¾¾åˆ°å¹³è¡¡ç‚¹"


overfitting è¿‡æ‹Ÿåˆ

æ›´å¤æ‚çš„æ¨¡å‹ï¼šæ›´å°çš„training error

- ä¼˜åŒ–ç›®æ ‡ï¼ŒåŠ å…¥æ­£åˆ™åŒ–é¡¹ï¼Œä½¿å¾—æ¨¡å‹æ›´ç®€å•
- early stopping

Ridge Regression: 

$$
\min_{\omega} \sum_{i=1}^n (y_i - \omega^T x_i)^2 + \lambda \|\omega\|^2
$$
ç®€ä»‹ï¼šå²­å›å½’



æ¬ æ‹Ÿåˆï¼šå¯¹è®­ç»ƒæ ·æœ¬çš„ä¸€èˆ¬æ€§è´¨æ²¡æœ‰å­¦å¥½
- å†³ç­–æ ‘ï¼šæ‹“å±•åˆ†æ”¯
- ç¥ç»ç½‘ç»œï¼šå¢åŠ è®­ç»ƒè½®æ•°
![](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/20240912105851.png)


### è¯„ä¼°æ–¹æ³•
ç†è§£æ–¹æ³•ï¼šé¢˜åº“å‡ºå°æµ‹é¢˜ç›®


#### **hold-out**ï¼š
- ç›´æ¥å°†æ•°æ®é›†åˆ’åˆ†ä¸ºä¸¤ä¸ªäº’æ–¥é›†åˆâ€”â€”è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚åœ¨åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ—¶ï¼Œè¦å°½å¯èƒ½ä¿æŒæ•°æ®åˆ†å¸ƒçš„ä¸€è‡´æ€§ã€‚
- ä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼ˆstratified samplingï¼‰æ–¹æ³•ï¼Œä»¥ä¿æŒç±»åˆ«æ¯”ä¾‹ä¸€è‡´ã€‚
- ä¸€èˆ¬è¿›è¡Œè‹¥å¹²æ¬¡éšæœºåˆ’åˆ†ï¼Œé‡å¤å®éªŒå¹¶å–å¹³å‡å€¼ã€‚
- è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ·æœ¬æ¯”ä¾‹é€šå¸¸ä¸º2:1æˆ–4:1ï¼Œæ•ˆæœè¿˜ä¸é”™ã€‚
![](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/20240912151812.png)
#### **äº¤å‰éªŒè¯æ³•**

1. åˆ†å±‚é‡‡æ ·åˆ’åˆ†æ•°æ®é›†ï¼šå°†æ•°æ®é›†åˆ†å±‚é‡‡æ ·åˆ’åˆ†ä¸ºKä¸ªå¤§å°ç›¸ä¼¼çš„äº’æ–¥å­é›†ã€‚
2. è®­ç»ƒå’Œæµ‹è¯•ï¼šæ¯æ¬¡ä½¿ç”¨K-1ä¸ªå­é›†çš„å¹¶é›†ä½œä¸ºè®­ç»ƒé›†ï¼Œå‰©ä¸‹çš„ä¸€ä¸ªå­é›†ä½œä¸ºæµ‹è¯•é›†ã€‚
3. é‡å¤å®éªŒï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹Kæ¬¡ï¼Œæ¯æ¬¡éƒ½ä½¿ç”¨ä¸åŒçš„å­é›†ä½œä¸ºæµ‹è¯•é›†ã€‚
4. è®¡ç®—å¹³å‡å€¼ï¼šæœ€ç»ˆè¿”å›Kä¸ªæµ‹è¯•ç»“æœçš„å¹³å‡å€¼
![](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/20240912152056.png)

LOO leave-one-outï¼šç•™ä¸€æ³•ï¼Œæœ€æ¥è¿‘äºç†æƒ³æƒ…å†µï¼Œå¼€é”€å¤ªå¤§ï¼ŒNFL

!!! tip "çŒœæµ‹è¿›æ•™å®¤æ€§åˆ«é—®é¢˜"
    ç”·ç”Ÿå¤šçŒœç”·ç”Ÿï¼Œå¥³ç”Ÿå¤šçŒœå¥³ç”Ÿ

#### è‡ªåŠ©æ³• bootstrap

åŒ…å¤–ä¼°è®¡ï¼Œæœ‰36.8%ä¸å‡ºç°
![](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/20240912152608.png)

- æ”¹å˜äº†æ•°æ®çš„åˆ†å¸ƒ

#### **è°ƒå‚æ•°**

- æ¨¡å‹å‚æ•°ï¼šç®—æ³•è®¡ç®—
- è¶…å‚æ•°ï¼šç”¨æˆ·æä¾›,è½®æ•°ï¼Œ


### æ€§èƒ½åº¦é‡
ä½œä¸ºè®¾è®¡è‡ªå·±åº¦é‡çš„ä¸€ç§å¯å‘

#### å›å½’

- MSE:
  
$$
MSE(f, \boldsymbol{\theta})=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-f\left(x_{i}, \boldsymbol{\theta}\right)\right)^{2}
$$

- MAE:

$$
MAE(f, \boldsymbol{\theta})=\frac{1}{n}\left|y_{i}-f\left(x_{i}, \boldsymbol{\theta}\right)\right|
$$







memory consumption

platform required for running 

CPU vs GPU

server,workstation

#### æ··æ·†çŸ©é˜µ

å…ˆä»‹ç»ä¸€ä¸‹æ··æ·†çŸ©é˜µï¼ˆT/F: é¢„æµ‹æ˜¯å¦æ­£ç¡®ï¼ŒP/Nï¼šé¢„æµ‹æ˜¯æ­£ç±»è¿˜æ˜¯è´Ÿç±»ï¼‰
- TPï¼šé¢„æµ‹ä¸ºæ­£ç±»ï¼Œå®é™…ä¸ºæ­£ç±»ï¼Œé¢„æµ‹æ­£ç¡®ã€‚
- FPï¼šé¢„æµ‹ä¸ºæ­£ç±»ï¼Œå®é™…ä¸ºè´Ÿç±»ï¼Œé¢„æµ‹é”™è¯¯ã€‚
- FNï¼šé¢„æµ‹ä¸ºè´Ÿç±»ï¼Œå®é™…ä¸ºæ­£ç±»ï¼Œé¢„æµ‹é”™è¯¯ã€‚
- TNï¼šé¢„æµ‹ä¸ºè´Ÿç±»ï¼Œå®é™…ä¸ºè´Ÿç±»ï¼Œé¢„æµ‹æ­£ç¡®ã€‚



**å‡†ç¡®ç‡ | Accuracy**

æ­£ç±»å’Œè´Ÿç±»ä¸­é¢„æµ‹æ­£ç¡®çš„æ•°é‡å æ€»æ•°é‡çš„å æ¯”ã€‚

$Accuracy=\frac{T P+T N}{T P+F P+F N+T N}$

=== "å­˜åœ¨é—®é¢˜1"
	å‡†ç¡®ç‡ä¸å¯å¯¼ï¼Œæ— æ³•ä½œä¸ºcost functionå»åšè®­ç»ƒï¼Œåªèƒ½ç”¨ä½œè¯„ä¼°ã€‚
=== "å­˜åœ¨é—®é¢˜2"
	æ­£ç±»å’Œè´Ÿç±»é¢„æµ‹æ­£ç¡®çš„é‡è¦æ€§ä¸ä¸€æ ·ï¼Œæ¯”å¦‚å¯¹äºç™Œç—‡æ£€æµ‹æ¥è¯´ï¼Œå¯èƒ½è´Ÿç±»(æ²¡æœ‰æ‚£ç™Œç—‡) é¢„æµ‹æ­£ç¡®çš„æ•°é‡éå¸¸å¤§ï¼Œå°±å¯¼è‡´Accuracyçš„åˆ†å­éå¸¸å¤§ï¼Œå¾—åˆ°çš„Accuracyå°±éå¸¸å¤§ï¼Œä½†æ˜¯å¯èƒ½æ­£ç±»(æ‚£ç™Œç—‡) é¢„æµ‹æ­£ç¡®çš„æ•°é‡éå¸¸å°ï¼Œå°±å¯¼è‡´è™½ç„¶æ¨¡å‹çš„å‡†ç¡®ç‡å¾ˆé«˜ï¼Œä½†æ ¹æœ¬æ£€æµ‹ä¸å‡ºç™Œç—‡ã€‚

è§£å†³é—®é¢˜çš„æ–¹æ¡ˆï¼šé‡‡ç”¨ç²¾ç¡®ç‡æˆ–è€…å¬å›ç‡

!!! tip "æŸ¥å‡†ç‡å’ŒæŸ¥å…¨ç‡"
    - æŸ¥å‡†ç‡ï¼šå³ä½ è®¤ä¸ºæ˜¯Trueçš„æ ·æœ¬ä¸­ï¼Œåˆ°åº•æœ‰å¤šå°‘ä¸ªæ ·æœ¬æ˜¯çœŸä¸ºTrueã€‚
    - æŸ¥å…¨ç‡ï¼šå³åœ¨é¢„æµ‹æ ·æœ¬ä¸­å±äºTrueçš„æ ·æœ¬ï¼Œä½ çœŸçš„åˆ¤æ–­ä¸ºTrueçš„æœ‰å‡ ä¸ªã€‚

- çœŸé˜³æ€§ç‡ï¼ˆTrue Positive Rateï¼ŒTPRï¼‰é€šå¸¸ä¹Ÿè¢«ç§°ä¸ºæ•æ„Ÿæ€§ï¼ˆSensitivityï¼‰æˆ–å¬å›ç‡ï¼ˆRecallï¼‰ã€‚å®ƒæ˜¯æŒ‡åˆ†ç±»å™¨æ­£ç¡®è¯†åˆ«æ­£ä¾‹çš„èƒ½åŠ›ã€‚çœŸé˜³æ€§ç‡å¯ä»¥ç†è§£ä¸ºæ‰€æœ‰é˜³æ€§ç¾¤ä½“ä¸­è¢«æ£€æµ‹å‡ºæ¥çš„æ¯”ç‡(1-æ¼è¯Šç‡)ï¼Œå› æ­¤TPRè¶Šæ¥è¿‘1è¶Šå¥½ã€‚å®ƒçš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š$precision=\frac{T P}{TP+FP}$



- å‡é˜³æ€§ç‡ (False Positive Rate, FPR)
å‡é˜³æ€§ç‡ï¼ˆFalse Positive Rateï¼ŒFPRï¼‰æ˜¯æŒ‡åœ¨æ‰€æœ‰å®é™…ä¸ºè´Ÿä¾‹çš„æ ·æœ¬ä¸­ï¼Œæ¨¡å‹é”™è¯¯åœ°é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ ·æœ¬æ¯”ä¾‹ã€‚å‡é˜³æ€§ç‡å¯ä»¥ç†è§£ä¸ºæ‰€æœ‰é˜´æ€§ç¾¤ä½“ä¸­è¢«æ£€æµ‹å‡ºæ¥é˜³æ€§çš„æ¯”ç‡(è¯¯è¯Šç‡)ï¼Œå› æ­¤FPRè¶Šæ¥è¿‘0è¶Šå¥½ã€‚å®ƒçš„è®¡ç®—å…¬å¼å¦‚ä¸‹ FP = \frac{FP}{FP+TN}

![](https://philfan-pic.oss-cn-beijing.aliyuncs.com/img/20240909154344.png)

[P-Ræ›²çº¿ç»˜åˆ¶åŸç†åŠä»£ç å®ç°\_æ±‚p-ræ›²çº¿çš„ä»£ç -CSDNåšå®¢](https://blog.csdn.net/weixin_43298886/article/details/110696655)


F1 åº¦é‡ï¼š

$F 1=\frac{2 \times \text { precision } \times \text { recall }}{\text { precision }+\text { recall }} = ã€\frac{2\times TP}{æ€»æ•° + TP -TN}$

!!! tip "F1æ˜¯På’ŒRçš„è°ƒå’Œå¹³å‡"

å¯¹æŸ¥å‡†ç‡ã€æŸ¥å…¨ç‡æœ‰ä¸åŒçš„åå¥½
$F_\beta = \frac{(1+\beta^2)\times P\times R}{(\beta^2 \times P) + R}$
$\beta = 1$:æ ‡å‡†F1

$\beta > 1$:åé‡æŸ¥å…¨ç‡ï¼ˆé€ƒçŠ¯ä¿¡æ¯æ£€ç´¢ï¼‰

$\beta < 1$:åé‡æŸ¥å‡†ç‡ï¼Œå•†å“æ¨èç³»ç»Ÿ

#### ROC & AUC
ç»˜åˆ¶æ–¹æ³•ï¼šç»™å®š$m^+$ä¸ªæ­£æ ·æœ¬å’Œ$m^-$ä¸ªè´Ÿæ ·æœ¬ï¼Œå¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œè®¡ç®—å…¶é¢„æµ‹æ¦‚ç‡ï¼Œç„¶åæŒ‰ç…§æ¦‚ç‡ä»å¤§åˆ°å°æ’åºï¼Œç„¶åé€ä¸ªæ ·æœ¬è®¡ç®—TP rateå’ŒFP rateï¼Œç„¶åç»˜åˆ¶ROCæ›²çº¿ã€‚

é¢„æµ‹å‡†ç¡®ï¼Œå¢åŠ yå€¼ï¼›é¢„æµ‹é”™è¯¯ï¼Œå¢åŠ xå€¼ï¼›

---

**AUC**

AUCï¼ˆROCæ›²çº¿ä¸‹é¢ç§¯ï¼‰æ˜¯ROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œç”¨äºè¡¡é‡åˆ†ç±»å™¨æ€§èƒ½ã€‚AUCå€¼è¶Šæ¥è¿‘1ï¼Œè¡¨ç¤ºåˆ†ç±»å™¨æ€§èƒ½è¶Šå¥½ï¼›åä¹‹ï¼ŒAUCå€¼è¶Šæ¥è¿‘0ï¼Œè¡¨ç¤ºåˆ†ç±»å™¨æ€§èƒ½è¶Šå·®ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸é€šè¿‡è®¡ç®—AUCå€¼æ¥è¯„ä¼°åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚

ç†è®ºä¸Šï¼Œå®Œç¾çš„åˆ†ç±»å™¨çš„AUCå€¼ä¸º1ï¼Œè€Œéšæœºåˆ†ç±»å™¨çš„AUCå€¼ä¸º0.5ã€‚è¿™æ˜¯å› ä¸ºå®Œç¾çš„åˆ†ç±»å™¨å°†æ‰€æœ‰çš„æ­£ä¾‹å’Œè´Ÿä¾‹å®Œå…¨æ­£ç¡®åœ°åˆ†ç±»ï¼Œè€Œéšæœºåˆ†ç±»å™¨å°†æ­£ä¾‹å’Œè´Ÿä¾‹çš„åˆ†ç±»ç»“æœéšæœºåˆ†å¸ƒåœ¨ROCæ›²çº¿ä¸Šã€‚

ç»¼ä¸Šï¼ŒROCæ›²çº¿å’ŒAUCå€¼æ˜¯ç”¨äºè¯„ä¼°äºŒåˆ†ç±»æ¨¡å‹æ€§èƒ½çš„ä¸¤ä¸ªé‡è¦æŒ‡æ ‡ã€‚é€šè¿‡ROCæ›²çº¿ï¼Œæˆ‘ä»¬å¯ä»¥ç›´è§‚åœ°äº†è§£åˆ†ç±»å™¨åœ¨ä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½ï¼›è€Œé€šè¿‡AUCå€¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹åˆ†ç±»å™¨çš„æ•´ä½“æ€§èƒ½è¿›è¡Œé‡åŒ–è¯„ä¼°ã€‚

### æ€§èƒ½è¯„ä»·

- æµ‹è¯•æ€§èƒ½ä¸ç­‰äºæ³›åŒ–æ€§èƒ½
- æµ‹è¯•æ€§èƒ½éšç€æµ‹è¯•é›†çš„å˜åŒ–è€Œå˜åŒ–

å‡è®¾æ£€éªŒï¼š
æœ‰å¤šå°‘æŠŠæ¡åœ¨ç»Ÿè®¡æ„ä¹‰ä¸Šè¯´è¿™ä¸ªæ¨¡å‹æ˜¯å¥½çš„




### bias and variance decomposition
åå·® & æ–¹å·®

- bias: æœ€å¥½çš„æ¨¡å‹å’Œground truthä¹‹é—´çš„å·®è·;æ¨¡å‹çš„ä¸Šé™; training error
- variance: æœ€ä¼˜çš„æ¨¡å‹å’Œæœ€å·®çš„æ¨¡å‹ä¹‹é—´çš„å·®è·ï¼›æ¨¡å‹çš„ä¸‹é™; the difference between training error and test error

prediction error = bias + variance + noise

- high bias, low variance: underfitting
- low bias, high variance: overfitting
- low bias, low variance: good model


æ”¹è¿›ç­–ç•¥

underfitting:
- add more features
- use more complex model
- descrease regularization

overfitting:
- decrease model complexity
- decrease number of features
- add more regularization
- add more data
!!! note "train val test"
    60% 20% 20%
    - training set: train the model
    - validation set: tune the hyperparameters
    - test set: evaluate the model



## è´å¶æ–¯å†³ç­–







## å­¦ä¹ èµ„æº

[Machine Learning in Practice Crash Course | Jinming Hu (conanhujinming.github.io)](https://conanhujinming.github.io/post/ml_in_practice_crash_course/)

[å®ç”¨çš„æœºå™¨å­¦ä¹  ç¬¬ä¸€è¯¾ æœºå™¨å­¦ä¹ å¯¼è®º 2024summer_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1Gw4m1i7ys/?spm_id_from=333.788.recommend_more_video.0&vd_source=8b7a5460b512357b2cf80ce1cefc69f5)

[æœºå™¨å­¦ä¹ 2023-10-19ç¬¬6-8èŠ‚ (zju.edu.cn)](https://classroom.zju.edu.cn/livingpage?course_id=53449&sub_id=915451&tenant_code=112)

èµµæ´²è€å¸ˆ







[æœ‰ç›‘ç£çš„æœºå™¨å­¦ä¹ ï¼šå›å½’ä¸åˆ†ç±» | Coursera](https://www.coursera.org/learn/machine-learning?action=enroll)

[CS229å´æ©è¾¾æœºå™¨å­¦ä¹ ](https://www.bilibili.com/video/BV16J411t71N)

[CS229: Machine Learning (stanford.edu)](https://cs229.stanford.edu/)



æ·±åº¦å­¦ä¹ 

[CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)ï¼šdeep learning for CV

[å›¾çµç­ã€Šæœºå™¨å­¦ä¹ ã€‹è¯¾ç¨‹æ€»ç»“ - CC98è®ºå›](https://www.cc98.org/topic/5599897)

æˆ‘åœ¨å¿ƒçµå­¦MLç³»åˆ—doge

[å†æ¬¡å…¥é—¨deep learningä»¥åŠä¸€äº›å›å¿†ï¼ˆæ›´æ–°ç¬¬äºŒéƒ¨åˆ†ï¼‰ - CC98è®ºå›](https://www.cc98.org/topic/5207160)

[å†æ¬¡å…¥é—¨deep learningï¼Œè¿™æ¬¡ç›´æ¥ä¸Šé‡ç‚¹ï¼ˆå®Œç»“ç¯‡ï¼‰ - CC98è®ºå›](https://www.cc98.org/topic/5208795)



å­”é™¢ğŸ•ğŸ¦è¯¾

[äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ å¤ä¹ èµ„æ–™ - CC98è®ºå›](https://www.cc98.org/topic/5518130)

[2022-2023ç§‹å†¬äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ çº¿ä¸Šè€ƒè¯•å›å¿†å·ï¼ˆå’Œå¤§ä½¬ä»¬å‘é‡äº†ï¼‰ - CC98è®ºå›](https://www.cc98.org/topic/5508899)

[äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ å›å¿†å· - CC98è®ºå›](https://www.cc98.org/topic/5234359)


### ä¼šè®®è®ºæ–‡
- ICML (International Conference on Machine
Learning)
- NeurIPS (Neural Information Processing Systems)
- KDD (ACM SIGKDD Conference on Knowledge Discovery and Data Mining)
- AAAI (AAAI conference on Artificial Intelligence)

æœ¬äººå†œå­¦åšå£«ï¼Œç§‘ç ”æ¥è§¦çš„æœºå™¨å­¦ä¹ ï¼Œä¹‹å‰æœ‰è®¡ç®—æœºçš„å¯¼å¸ˆé¢†å…¥é—¨äº†ã€‚ä¸ªäººç›®å‰é‡åˆ°æœ€å¥½çš„æ•™ç¨‹æ˜¯å´æ©è¾¾çš„è§†é¢‘è¯¾ç¨‹ï¼Œå› ä¸ºä»–å……åˆ†è€ƒè™‘åˆ°äº†å­¦ç”Ÿçš„æ°´å¹³ï¼ŒæŠŠéœ€è¦çš„æ•°å­¦çŸ¥è¯†ä¹Ÿè®²äº†ï¼Œå…ˆçœ‹äº†å´æ©è¾¾æ—©æœŸçš„æœºå™¨å­¦ä¹ ï¼ˆåå‘ä¼ æ’­çš„é‚£èŠ‚è®²çš„ä¸æ˜¯å¾ˆå¥½ï¼‰ï¼Œç„¶åè¿‘ä¸¤å¹´çš„æ·±åº¦å­¦ä¹ ï¼Œåœ¨çœ‹äº†bç«™åŒ—å¤§çš„tensorflowç¬”è®°è¯¾ç¨‹ï¼Œè§‰å¾—è‡³å°‘çŸ¥é“è¯¥æ€ä¹ˆåšæœºå™¨å­¦ä¹ ï¼ˆåŒ…æ‹¬æ·±åº¦å­¦ä¹ ï¼‰äº†ã€‚ ä¸è¿‡ä½œä¸ºä¸€ä¸ªéè®¡ç®—æœºä¸“ä¸šçš„å­¦ç”Ÿï¼Œä¸ªäººè§‰å¾—æ‰€æœ‰çš„æ•™ç¨‹éƒ½å¿½è§†äº†ä¸€ä¸ªæœ€åŸºç¡€ä½†æ˜¯ä¹Ÿæ˜¯æœ€é‡è¦çš„ä¸œè¥¿â€”â€”**ç‰¹å¾å·¥ç¨‹**ï¼ŒæŒ‡çš„ä¸æ˜¯ç‰¹å¾é€‰æ‹©ï¼ˆæ— ç›‘ç£å­¦ä¹ çš„é™ç»´ï¼‰ï¼Œè€Œæ˜¯ç‰¹å¾è¡¨å¾ï¼ˆfeature representï¼‰ï¼Œæ·±åº¦å­¦ä¹ é‡Œé¢å«embeddingï¼ˆè‡ªå·±çœ‹äº†åŠŸèƒ½åç†è§£çš„ï¼‰ï¼Œå°±æ˜¯æˆ‘ä»¬åº”è¯¥æ€æ ·å»è¡¨å¾é—®é¢˜ï¼Œå°†é—®é¢˜çš„ä¿¡æ¯è¡¨ç¤ºä¸ºæ•°æ®ç»™è®¡ç®—æœºè¿›è¡Œå­¦ä¹ ã€‚ä¹‹å‰çœ‹äº†ä»€ä¹ˆæœ‰ç›‘ç£å­¦ä¹ å•Šï¼Œæ— ç›‘ç£å­¦ä¹ å•Šï¼Œå¯¹ç‰¹å¾å°±æ˜¯å‘Šè¯‰ä½ æ ·æœ¬æˆ–å‘é‡ç©ºé—´ï¼Œå®Œå…¨ä¸çŸ¥é“æœºå™¨å­¦ä¹ å»åšä»€ä¹ˆã€‚åªåˆ°æœ‰ä¸ªè€å¸ˆè®©æˆ‘åœ¨åšäº†ç‰¹å¾æå–ï¼Œç„¶åé™ç»´ï¼Œç„¶ååˆ†ç±»æˆ–é¢„æµ‹çš„æ—¶å€™æˆ‘æ‰æ˜ç™½æœºå™¨å­¦ä¹ æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„è¿‡ç¨‹ã€‚



æˆ‘æ˜¯å…¥é—¨çœ‹çš„å’±ä»¬å­¦æ ¡çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œå¯¹æœºå™¨å­¦ä¹ å¤§æ¦‚æœ‰ä¸ªäº†è§£ï¼Œæ²¡å¤ªå…³å¿ƒæ•°å­¦ã€‚ è¯´å®è¯è¿™äº›ç®—æ³•ï¼ˆmlé‡Œä¸åŒ…å«dlçš„é‚£äº›ï¼‰æˆ‘ç§‘ç ”ä¸Šç”¨åˆ°çš„æ¯”è¾ƒå°‘ï¼Œåæ¥éšç€ç§‘ç ”çš„æ·±å…¥ä¼šå»æ€è€ƒè¿™äº›ç®—æ³•åé¢çš„æ•°å­¦åŸç†ï¼Œå°±å»å‚è€ƒæèˆªçš„æœºå™¨å­¦ä¹ ï¼Œè¥¿ç“œä¹¦ã€‚æ›´åŠ é«˜å±‹å»ºç“´ä¸€ç‚¹çš„æ•™æå°±æ˜¯PRMLäº†ã€‚ æˆ‘æ¯”è¾ƒæ¨èUCBçš„CS188ï¼Œä»æ•´ä¸ªäººå·¥æ™ºèƒ½çš„è§’åº¦è®²é—®é¢˜ï¼Œæœºå™¨å­¦ä¹ æ˜¯å…¶ä¸­çš„ä¸€ä¸ªéƒ¨åˆ†ã€‚ç¼–ç¨‹é¡¹ç›®æœ‰è¶£è¿è´¯ã€‚ç”¨çš„æ•™æä¹Ÿæ˜¯ç»å…¸ï¼Œä¸€äº›æ€æƒ³ç°åœ¨ä¹Ÿä¸è¿‡æ—¶ã€‚



pipeline

å®Œæˆå®ç”¨æœºå™¨å­¦ä¹ çš„æ‰€æœ‰ä½œä¸š

å®Œæˆèµµæ´²è€å¸ˆçš„æ‰€æœ‰ä½œä¸š+å¤§ä½œä¸š

